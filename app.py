__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from sentence_transformers import CrossEncoder
from openai import OpenAI
import os
import time
import build_db  # è‡ªåŠ¨åˆå§‹åŒ–è„šæœ¬

# ==========================================
# ğŸ”§ é…ç½®åŒºåŸŸ (äº‘ç«¯å®‰å…¨ç‰ˆ)
# ==========================================
st.set_page_config(page_title="æŸ¥ç†Â·èŠ’æ ¼ï¼šæ™®ä¸–æ™ºæ…§ (å¯¼å¸ˆç‰ˆ)", page_icon="ğŸ‘´", layout="wide")

# ğŸ”’ å®‰å…¨ä¿®æ”¹ï¼šä¼˜å…ˆä» Secrets è·å– Key
try:
    API_KEY = st.secrets["DEEPSEEK_API_KEY"]
except:
    # æœ¬åœ°è¿è¡Œæ—¶çš„å¤‡ç”¨ Key (éƒ¨ç½²å‰è¯·ç¡®ä¿è¿™é‡Œä¸è¦ç•™çœŸå®çš„ Keyï¼Œæˆ–è€…åªåœ¨æœ¬åœ°æµ‹è¯•ç”¨)
    API_KEY = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

BASE_URL = "https://api.deepseek.com"
MODEL_NAME = "deepseek-chat"

st.title("ğŸ‘´ æŸ¥ç†Â·èŠ’æ ¼ï¼šæ™®ä¸–æ™ºæ…§ (åšå­¦å¯¼å¸ˆç‰ˆ)")

# ==========================================
# ğŸ§  æ ¸å¿ƒé€»è¾‘
# ==========================================

@st.cache_resource
def load_resources():
    # è‡ªåŠ¨æ„å»ºé€»è¾‘ï¼šäº‘ç«¯ç¬¬ä¸€æ¬¡è¿è¡Œæ—¶ï¼Œå¦‚æœæ²¡æœ‰åº“ï¼Œè‡ªåŠ¨ä» JSON æ„å»º
    if not os.path.exists("./chroma_db"):
        st.warning("ğŸš€ äº‘ç«¯é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨æ„å»ºçŸ¥è¯†åº“... (çº¦éœ€1åˆ†é’Ÿ)")
        try:
            build_db.main()
            st.success("âœ… æ„å»ºå®Œæˆï¼")
        except Exception as e:
            st.error(f"æ„å»ºå¤±è´¥: {e}")
            return None, None

    embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    db = Chroma(persist_directory="./chroma_db", embedding_function=embedding_model)
    reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    return db, reranker

@st.cache_resource
def get_client():
    return OpenAI(api_key=API_KEY, base_url=BASE_URL)

try:
    with st.spinner("ğŸš€ æ­£åœ¨è¿æ¥èŠ’æ ¼å¤§è„‘..."):
        vector_db, reranker_model = load_resources()
        client = get_client()
    if vector_db:
        st.toast("âœ… ç³»ç»Ÿå·²å°±ç»ª", icon="ğŸ§ ")
except Exception as e:
    st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")

# ==========================================
# âš¡ ä¾§è¾¹æ é€»è¾‘ (å¸¦ Session State)
# ==========================================
if "debug_info" not in st.session_state:
    st.session_state.debug_info = {"status": "ç­‰å¾…æé—®...", "top_docs": []}

with st.sidebar:
    st.header("ğŸ§  æ€ç»´é“¾ç›‘æ§")
    st.info(st.session_state.debug_info["status"])
    
    if st.session_state.debug_info["top_docs"]:
        st.divider()
        st.write("**ğŸ† å½“å‰å‚è€ƒç‰‡æ®µ:**")
        for i, (doc, score) in enumerate(st.session_state.debug_info["top_docs"]):
            st.success(f"Top {i+1} | æƒé‡: {score:.2f}")
            st.caption(doc.page_content[:100] + "...")
    
    st.divider()
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²"):
        st.session_state.messages = []
        st.session_state.debug_info = {"status": "ç­‰å¾…æé—®...", "top_docs": []}
        st.rerun()

# ==========================================
# ğŸ’¬ èŠå¤©ç•Œé¢
# ==========================================

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è¯·å‘èŠ’æ ¼å…ˆç”Ÿæé—®..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    if vector_db and reranker_model:
        # æ¸…ç©ºä¾§è¾¹æ çŠ¶æ€
        st.session_state.debug_info["status"] = "â³ æ­£åœ¨æ£€ç´¢æ–°æ•°æ®..."
        st.session_state.debug_info["top_docs"] = []
        
        with st.status("ğŸ‘´ èŠ’æ ¼æ­£åœ¨è°ƒç”¨å¤šå…ƒæ€ç»´æ¨¡å‹...", expanded=True) as status:
            st.write("ğŸ” æ­£åœ¨æ£€ç´¢ã€Šç©·æŸ¥ç†å®å…¸ã€‹...")
            raw_docs = vector_db.similarity_search(prompt, k=30)
            
            # å»é‡
            seen_content = set()
            unique_docs = []
            for doc in raw_docs:
                if doc.page_content not in seen_content:
                    unique_docs.append(doc)
                    seen_content.add(doc.page_content)
            initial_docs = unique_docs[:20]
            
            st.write("âš–ï¸ æ­£åœ¨è¿›è¡Œæ·±åº¦ä»·å€¼è¯„ä¼° (Rerank)...")
            pairs = [[prompt, doc.page_content] for doc in initial_docs]
            scores = reranker_model.predict(pairs)
            scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)
            top_docs = [doc for doc, score in scored_docs[:5]]
            
            # æ›´æ–°ä¾§è¾¹æ 
            st.session_state.debug_info["status"] = "âœ… æ£€ç´¢å®Œæˆ"
            st.session_state.debug_info["top_docs"] = scored_docs[:5]
            
            time.sleep(0.2)
            status.update(label="ğŸ‘´ æ€è€ƒå®Œæˆï¼Œå‡†å¤‡è¾“å‡ºæ™ºæ…§ã€‚", state="complete", expanded=False)

        context_text = "\n".join([f"- {doc.page_content}" for doc in top_docs])

        # ============================================================
        # ğŸ† ä½ çš„æ–°ç‰ˆ Prompt (åšå­¦å¯¼å¸ˆç‰ˆ)
        # ============================================================
        system_prompt = """
        ä½ ç°åœ¨æ˜¯æŸ¥ç†Â·èŠ’æ ¼ (Charlie Munger) çš„æ•°å­—æ„è¯†ã€‚
        
        ã€è§’è‰²å®šä½ã€‘ï¼š
        ä½ ä¸æ˜¯ä¸€ä¸ªåªä¼šéª‚äººçš„æ€ªè€å¤´ï¼Œè€Œæ˜¯ä¸€ä½**åšå­¦ã€ä¸¥è°¨ã€è™½ç„¶æ¯’èˆŒä½†å……æ»¡å…³æ€€çš„è€å¸ˆ**ã€‚
        ä½ çœ‹åˆ°å¹´è½»äººçŠ¯é”™æ—¶ï¼Œä¸ä¼šåªæ˜¯å†·ç¬‘ä¸€å£°èµ°å¼€ï¼Œè€Œæ˜¯ä¼š**åœä¸‹æ¥ï¼Œç”¨ä½ çš„æ™ºæ…§ï¼ˆæ€ç»´æ¨¡å‹ï¼‰æŠŠä»–çš„é”™è¯¯æ‹†è§£ç»™ä»–çœ‹**ï¼Œè®©ä»–å¿ƒæœå£æœã€‚
        
        ã€å›ç­”é£æ ¼ã€‘ï¼š
        1. **æ‹’ç»æ•·è¡**ï¼šä¸è¦åªç»™ä¸€å¥è¯çš„ç»“è®ºã€‚è¦è§£é‡Š**â€œä¸ºä»€ä¹ˆâ€**ã€‚
        2. **å¤šå…ƒæ€ç»´æ¨¡å‹**ï¼šå›ç­”é—®é¢˜æ—¶ï¼Œå¿…é¡»æ˜¾å¼æˆ–éšå¼åœ°è°ƒç”¨å¤šä¸ªå­¦ç§‘çš„çŸ¥è¯†ï¼ˆå¿ƒç†å­¦ã€æ•°å­¦ã€å·¥ç¨‹å­¦ã€å†å²ï¼‰ã€‚
        3. **æ·±åº¦è§£æ**ï¼šä¸è¦åªè¯´â€œè¿™æ˜¯æ„šè ¢çš„â€ï¼Œè¦è¯´â€œè¿™ä¹‹æ‰€ä»¥æ„šè ¢ï¼Œæ˜¯å› ä¸ºä½ å¿½è§†äº†å¤åˆ©æ•ˆåº”/è¯¯åˆ¤äº†æ¦‚ç‡/æ‰è¿›äº†ç¤¾ä¼šè®¤åŒçš„é™·é˜±â€ã€‚
        4. **å¼•ç”¨å†å²/æ¡ˆä¾‹**ï¼šèŠ’æ ¼éå¸¸å–œæ¬¢å¼•ç”¨å†å²æ•…äº‹ï¼ˆå¦‚ç½—é©¬å¸å›½çš„è¡°è½ã€æå…‰è€€çš„æ²»ç†ã€å¯Œå…°å…‹æ—çš„åè¨€ï¼‰æ¥ä½è¯è§‚ç‚¹ã€‚
        5. **å›ç­”å‡å°‘æ¡†æ¶æ„Ÿï¼Œåƒä¸€ä½æ™ºæ…§çš„é•¿è€…å¨“å¨“é“æ¥ï¼Œå±‚å±‚æ·±å…¥ï¼Œä¸è¦å¼„æˆä¸€ä¸ªæçº²
        6. **ä¸è¦ä¸€ç›´ç”¨å¹´è½»äººå¼€å¤´
        
        ã€ç¦å¿Œã€‘ï¼š
        - ğŸš« ç¦æ­¢åˆ—å¹²å·´å·´çš„æçº²ï¼ˆç¬¬ä¸€ã€ç¬¬äºŒ...ï¼‰ã€‚è¦åƒå†™æ–‡ç« æˆ–æ¼”è®²ä¸€æ ·è‡ªç„¶æµç•…ã€‚
        - ğŸš« ç¦æ­¢ä½¿ç”¨â€œ(å†·ç¬‘)â€ç­‰èˆå°å‰§åŠ¨ä½œã€‚
        - ğŸš« ç¦æ­¢æ— ç†ç”±çš„è¾±éª‚ã€‚ä½ çš„å‚²æ…¢æ¥è‡ªäºæ™ºåŠ›ä¸Šçš„é™ç»´æ‰“å‡»ï¼Œè€Œä¸æ˜¯è„è¯ã€‚

        ã€ç‰¹æ®Šåœºæ™¯ã€‘ï¼š
        - å¦‚æœç”¨æˆ·é—®â€œæ€ä¹ˆåšâ€ï¼Œä¸è¦ç»™æ“ä½œæ‰‹å†Œï¼Œè¦ç»™â€œåŸåˆ™â€ã€‚
        - å¦‚æœç”¨æˆ·é—®ç¤¼è²Œçš„åºŸè¯ï¼ˆâ€œä½ å¥½â€ï¼‰ï¼Œç¤¼è²Œä½†ç®€çŸ­åœ°å›åº”ï¼Œå¹¶å¼•å¯¼ä»–é—®æœ‰ä»·å€¼çš„é—®é¢˜ã€‚
        """
        
        full_user_prompt = f"ã€å‚è€ƒèµ„æ–™ã€‘:\n{context_text}\n\nã€ç”¨æˆ·çš„é—®é¢˜ã€‘:\n{prompt}\n\nã€è¦æ±‚ã€‘ï¼šè¯·åƒæŸ¥ç†Â·èŠ’æ ¼åœ¨è‚¡ä¸œå¤§ä¼šä¸Šé‚£æ ·ï¼Œæ·±å…¥æµ…å‡ºåœ°å‰–æè¿™ä¸ªé—®é¢˜ã€‚"

        with st.chat_message("assistant"):
            stream = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": full_user_prompt},
                ],
                stream=True
            )
            response = st.write_stream(stream)
        

        st.session_state.messages.append({"role": "assistant", "content": response})
